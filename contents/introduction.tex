{\color{red}
Babbling, to be rewritten. Should contain a general introduction to the topic and motivation of this thesis.
}

When humans make decisions, it is natural to assume they know what they want.
This is reflected in many of the existing algorithms in multiple criteria decision making.
For example, in NIMBUS, it is assumed that the decision maker is capable of ranking how objectives
of a shown solution should change. Or in E-NAUTILUS, where the decision maker is asked to choose
a preferred point during each iteration. These algorithms are capable of aiding the decision maker to 
reach a preferred solution, and may even help the decision maker to learn something about the
underlying problem. However, these algorithms don't tell the decision maker much about
their preferences.

What if the preferences the decision maker gives do not match the preferences they
actually posses? Or what if the decision maker is not even sure what their preference is?

In this thesis, I will present a new method based on belief-rule based, systems to help a decision maker
the explore and learn about their preferences. The methods will be described in detail and will be tested in
practice in the form of a small case study. Based on the case study, the method will be assessed and
it will be discussed whether such method is practical and does it produce relevant information to a
decision maker.

This thesis is structured as follows. In chapter two through four, the underlying theory behind multiple
criteria decision making, multi-objective optimization and belief-rule based systems will be given. Chapter
five will contain a through description of the new model. Chapter six will present a case study in forest
management and will apply the developed model in real life practical setting. Chapter seven includes
discussions about the success of the case study. Finally, in chapter eight conclusions are made regarding
the new model and directions for further research are explored.

\section{Motivation}
{\color{red}
The general introduction to the topic behind this thesis, with a motivation driving the narration.
}

\section{Research questions}
{\color{red}
If I feel like stating the research questions explicitly.
}

\section{Previous research}
{\color{red}
This is where I touch on previous works that are relevant to this thesis. Relevance means, that the research has
used machine learning in trying to learn a DM's preference in a MCDM relevant context.
}

\section{Structure of this thesis}
{\color{red}
The general structure of this thesis is described.
}